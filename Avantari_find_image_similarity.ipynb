{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avantari_find_image_similarity.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hRTa3Ee15WsJ"
      },
      "source": [
        "# Image feature Extraction Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dQHMcypT3vDT"
      },
      "source": [
        "    * Tapan Kumar Patro\n",
        "    * tapankumarpatro05@gmail.com\n",
        "\n",
        "## Work Items:\n",
        "    1.Image Load\n",
        "    2.Feature Extraction for all Image\n",
        "    3.Save into A pickel file\n",
        "    4.Load the pickel file\n",
        "    5.Extract feature from given image\n",
        "    6.Find the minimum distance and return the images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKIpkNdb-OpJ",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBMcobPHdD8O",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "# from google_images_download import google_images_download\n",
        "\n",
        "try:\n",
        "  # The %tensorflow_version magic only works in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NOG3l_MsBO1A",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNnr21w1Y12Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dense,AveragePooling2D,BatchNormalization,Conv2D,Input,Flatten,Activation,concatenate,Dropout,GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v77rlkCKW0IJ"
      },
      "source": [
        "## Setup Google Colab for importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLPn-oPUFxKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta-fKS_NFyAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Navigating to Dataset folder in my drive\n",
        "path = 'drive/My Drive/PocketApps/Avantari/dataset'\n",
        "os.chdir(path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tx4wtJEQSgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t8tbqSpZELj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xhH5PF4ZQrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a list of all images\n",
        "all_images = os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTohu1bXOCd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining Image Size given in requirement\n",
        "IMAGE_SIZE = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pEdr2yUOlah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image, ImageOps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySaaG9JHOKRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Showing some random 3 images to visualize\n",
        "for i, val in enumerate(all_images[10:13]):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    image_data = Image.open(val)\n",
        "    plt.imshow(image_data)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OkH-kazQecHB"
      },
      "source": [
        "## Create the base model from the pre-trained convnets\n",
        "\n",
        "Create the base model from the **MobileNet V2** model developed at Google, and pre-trained on the ImageNet dataset, a large dataset of 1.4M images and 1000 classes of web images.\n",
        "\n",
        "First, pick which intermediate layer of MobileNet V2 will be used for feature extraction. A common practice is to use the output of the very last layer before the flatten operation, the so-called \"bottleneck layer\". The reasoning here is that the following fully-connected layers will be too specialized to the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
        "\n",
        "Let's instantiate an MobileNet V2 model pre-loaded with weights trained on ImageNet. By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top, which is ideal for feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "19IQ2gqneqmS",
        "colab": {}
      },
      "source": [
        "# Creating Base Model\n",
        "\n",
        "\n",
        "# Defining Image Shape\n",
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False, \n",
        "                                              weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rlx56nQtfe8Y"
      },
      "source": [
        "## Feature extraction\n",
        "You will freeze the convolutional base created from the previous step and use that as a feature extractor, we will train extra 20 more layers to get the features out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tts8BbAtRGvk",
        "colab": {}
      },
      "source": [
        "# base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX0kjw2Bgnl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine tune from this layer onwards\n",
        "fine_tune_at = 20\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "schSUlZWmuAC",
        "colab_type": "text"
      },
      "source": [
        "## Creating sequestial model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eApvroIyn1K0",
        "colab": {}
      },
      "source": [
        "# Creating Sequential model with MobileNetV2 Base model\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(), #Adding Pooling layer to better featuer extraction\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g0ylJXE_kRLi"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "You must compile the model before training it.  Since there are two classes, use a binary cross-entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RpR8HdyMhukJ",
        "colab": {}
      },
      "source": [
        "# Compiling Sequential Model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I8ARiyMFsgbH",
        "colab": {}
      },
      "source": [
        "# Summary of the new Model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "krvBumovycVA",
        "colab": {}
      },
      "source": [
        "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI5Wlx9kcwND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path+\"/\"+all_images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQni-InSnSDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image processing and getting the features\n",
        "image = Image.open(all_images[0])\n",
        "# Expanding array shape so that we can get the array\n",
        "image = np.expand_dims(image, axis=0) \n",
        "# Making the data computation easy\n",
        "image = image/127.5\n",
        "image = image - 1.0\n",
        "# Extracting features with our model\n",
        "feature = model.predict(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRvsfggbiiae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(feature[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU6nog6Pv3oX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVGHVatoxBDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating function for doing the feature extraction\n",
        "def cal_feature(image_data):\n",
        "    image = Image.open(image_data)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = image/127.5\n",
        "    image = image - 1.0\n",
        "    feature = model.predict(image)\n",
        "    return feature\n",
        "\n",
        "# Created function for saving the extracted feature \n",
        "def pickle_stuff(filename, stuff):\n",
        "    save_stuff = open(filename, \"wb\")\n",
        "    pickle.dump(stuff, save_stuff)\n",
        "    save_stuff.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPNxLRgDthGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computing features for all images\n",
        "\n",
        "precompute_features = []\n",
        "\n",
        "for image_name in tqdm(all_images_listed):\n",
        "    name = image_name\n",
        "    features = cal_feature(image_name)\n",
        "    precompute_features.append({\"name\": name, \"features\": features})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcr-3Z1xthCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the Computed features for all images into pickle file\n",
        "pickle_stuff(\"precompute_img_features.pickle\", precompute_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHE-IHQYSsKL",
        "colab_type": "text"
      },
      "source": [
        "# Now as the feature are saved .. now Need to load and find out Similar Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--hkLcziFQR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading pickle file\n",
        "\n",
        "def load_stuff(filename):\n",
        "    saved_stuff = open(filename, \"rb\")\n",
        "    stuff = pickle.load(saved_stuff)\n",
        "    saved_stuff.close()\n",
        "    return stuff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdccq2THFQIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precompute_features = load_stuff(\"precompute_img_features.pickle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwc8Pu1xJeMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How the pickle file looks like ?\n",
        "\n",
        "precompute_features[:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE4LVuj8Hsle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy as sp\n",
        "from scipy import spatial\n",
        "from scipy.spatial import distance\n",
        "from heapq import nsmallest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbxG9xgawkjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding Similar Images\n",
        "def find_similar_image(path, count):\n",
        "    distances = []\n",
        "    image_name_list = []\n",
        "\n",
        "\n",
        "    feature = cal_feature(path)\n",
        "            \n",
        "    for each_image_data in precompute_features:\n",
        "        image_feature = each_image_data.get(\"features\")\n",
        "        eucl_dist = distance.euclidean(image_feature, feature)\n",
        "        # eucl_dist = np.linalg.norm(image_feature, feature)\n",
        "        distances.append(eucl_dist)\n",
        "\n",
        "    # distances = distances.sort()\n",
        "    min_distance_value = min(distances)\n",
        "    print(\"The lowest distance for given Image {}\".format(min_distance_value))\n",
        "    min_distance_index = distances.index(min_distance_value)\n",
        "    print(\"The lowest distance for given Image index {}\".format(min_distance_index))\n",
        "    print(\"The lowest distance for given Image name {}\".format(precompute_features[min_distance_index].get(\"name\")))\n",
        "    \n",
        "    for dis in nsmallest(3, distances):\n",
        "        each_index = distances.index(dis)\n",
        "        image_name = precompute_features[each_index].get(\"name\")\n",
        "        image_name_list.append(image_name)\n",
        "\n",
        "    return image_name_list\n",
        "        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIsAgpOGH6Rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_list = find_similar_image(all_images[11], 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysh7tlOPJDKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHj2APRBTLjI",
        "colab_type": "text"
      },
      "source": [
        "## Lets take a sample Image "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyXbNaINJJHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_data = Image.open(all_images[11])\n",
        "plt.imshow(image_data)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZIeWaPbTato",
        "colab_type": "text"
      },
      "source": [
        "## Here are the similar Images What it gets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZGUWDFGwkfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img in list(image_list):\n",
        "    image_data = Image.open(img)\n",
        "    plt.imshow(image_data)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EANkQGfwka6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so8U3pnqwkWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}